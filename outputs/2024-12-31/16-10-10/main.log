[2024-12-31 16:10:10,762][flwr][WARNING] - DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.
	Instead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:

		$ flwr new  # Create a new Flower app from a template

		$ flwr run  # Run the Flower app in Simulation Mode

	Using `start_simulation()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[2024-12-31 16:10:10,763][flwr][INFO] - Starting Flower simulation, config: num_rounds=10, no round_timeout
[2024-12-31 16:10:15,568][flwr][INFO] - Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'CPU': 8.0, 'object_store_memory': 3710818713.0, 'memory': 7421637428.0, 'node:192.168.100.172': 1.0}
[2024-12-31 16:10:15,569][flwr][INFO] - Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html
[2024-12-31 16:10:15,569][flwr][INFO] - Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 0.0}
[2024-12-31 16:10:15,589][flwr][INFO] - Flower VCE: Creating VirtualClientEngineActorPool with 4 actors
[2024-12-31 16:10:15,589][flwr][INFO] - [INIT]
[2024-12-31 16:10:15,589][flwr][INFO] - Requesting initial parameters from one random client
[2024-12-31 16:10:19,969][flwr][INFO] - Received initial parameters from one random client
[2024-12-31 16:10:19,969][flwr][INFO] - Starting evaluation of initial global parameters
[2024-12-31 16:10:21,722][flwr][INFO] - initial parameters (loss, other metrics): 181.92612600326538, {'accuracy': 0.0897}
[2024-12-31 16:10:21,722][flwr][INFO] - 
[2024-12-31 16:10:21,722][flwr][INFO] - [ROUND 1]
[2024-12-31 16:10:21,722][flwr][INFO] - configure_fit: strategy sampled 10 clients (out of 100)
[2024-12-31 16:10:28,264][flwr][INFO] - aggregate_fit: received 10 results and 0 failures
[2024-12-31 16:10:28,264][flwr][ERROR] - division by zero
[2024-12-31 16:10:28,266][flwr][ERROR] - Traceback (most recent call last):
  File "/home/tulio/miniconda3/envs/flenv/lib/python3.9/site-packages/flwr/simulation/legacy_app.py", line 359, in start_simulation
    hist = run_fl(
  File "/home/tulio/miniconda3/envs/flenv/lib/python3.9/site-packages/flwr/server/server.py", line 492, in run_fl
    hist, elapsed_time = server.fit(
  File "/home/tulio/miniconda3/envs/flenv/lib/python3.9/site-packages/flwr/server/server.py", line 115, in fit
    res_fit = self.fit_round(
  File "/home/tulio/miniconda3/envs/flenv/lib/python3.9/site-packages/flwr/server/server.py", line 251, in fit_round
    ] = self.strategy.aggregate_fit(server_round, results, failures)
  File "/home/tulio/miniconda3/envs/flenv/lib/python3.9/site-packages/flwr/server/strategy/fedavg.py", line 235, in aggregate_fit
    aggregated_ndarrays = aggregate_inplace(results)
  File "/home/tulio/miniconda3/envs/flenv/lib/python3.9/site-packages/flwr/server/strategy/aggregate.py", line 52, in aggregate_inplace
    [fit_res.num_examples / num_examples_total for _, fit_res in results]
  File "/home/tulio/miniconda3/envs/flenv/lib/python3.9/site-packages/flwr/server/strategy/aggregate.py", line 52, in <listcomp>
    [fit_res.num_examples / num_examples_total for _, fit_res in results]
ZeroDivisionError: division by zero

[2024-12-31 16:10:28,266][flwr][ERROR] - Your simulation crashed :(. This could be because of several reasons. The most common are: 
	 > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: 
		 - You might be using a class attribute in your clients that hasn't been defined.
		 - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).
		 - The return types of methods in your clients/strategies might be incorrect.
	 > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.
	 > All the actors in your pool crashed. This could be because: 
		 - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 2, 'num_gpus': 0.0} is not enough for your run). Use fewer concurrent actors. 
		 - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 2, 'num_gpus': 0.0}.
Take a look at the Flower simulation examples for guidance <https://flower.ai/docs/framework/how-to-run-simulations.html>.
